{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# \ud83e\uddec Iseer Architecture Training\n",
        "\n",
        "**Mamba SSM + Mixture of Experts \u2014 From Scratch**\n",
        "\n",
        "Built by Iseer & Co.\n",
        "\n",
        "---\n",
        "\n",
        "\u26a0\ufe0f **Before running:** Go to Runtime > Change runtime type > GPU (T4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1\ufe0f\u20e3 Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deps"
      },
      "outputs": [],
      "source": [
        "!pip install -q einops datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone"
      },
      "outputs": [],
      "source": [
        "!rm -rf IseerArchitecture\n",
        "!git clone https://github.com/InanXR/IseerArchitecture.git\n",
        "%cd IseerArchitecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-head"
      },
      "source": [
        "## 2\ufe0f\u20e3 Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from iseer.model.config import ISEER_SM\n",
        "from iseer.model.iseer import Iseer\n",
        "from iseer.tokenizer.bpe import BPETokenizer\n",
        "\n",
        "tokenizer = BPETokenizer.load('iseer/tokenizer/vocab.json')\n",
        "print(f'Vocab: {len(tokenizer):,}')\n",
        "\n",
        "config = ISEER_SM\n",
        "config.vocab_size = len(tokenizer)\n",
        "model = Iseer(config)\n",
        "\n",
        "total, active = model.count_parameters()\n",
        "print(f'Total: {total:,} | Active: {active:,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-head"
      },
      "source": [
        "## 3\ufe0f\u20e3 Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "texts = []\n",
        "\n",
        "print('Loading FineWeb-Edu...')\n",
        "ds = load_dataset('HuggingFaceFW/fineweb-edu-score-2', 'default', split='train', streaming=True)\n",
        "\n",
        "for i, item in enumerate(tqdm(ds, total=10000)):\n",
        "    if i >= 10000:\n",
        "        break\n",
        "    texts.append(item['text'][:2000])\n",
        "\n",
        "print(f'Loaded {len(texts):,} texts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loader"
      },
      "outputs": [],
      "source": [
        "from iseer.data.dataset import create_dataloader\n",
        "\n",
        "train_loader = create_dataloader(\n",
        "    texts=texts,\n",
        "    tokenizer=tokenizer,\n",
        "    batch_size=8,\n",
        "    seq_len=512,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-head"
      },
      "source": [
        "## 4\ufe0f\u20e3 Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "from iseer.training.trainer import Trainer, TrainingConfig\n",
        "\n",
        "train_config = TrainingConfig(\n",
        "    learning_rate=3e-4,\n",
        "    max_steps=5000,\n",
        "    warmup_steps=100,\n",
        "    batch_size=8,\n",
        "    gradient_accumulation_steps=4,\n",
        "    mixed_precision=True,\n",
        "    log_steps=50,\n",
        "    save_steps=1000,\n",
        "    output_dir='checkpoints',\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, train_dataloader=train_loader, config=train_config)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save-head"
      },
      "source": [
        "## 5\ufe0f\u20e3 Save & Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'iseer_sm_trained.pt')\n",
        "print('Saved!')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('iseer_sm_trained.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}