{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üß¨ Iseer Architecture Training\n",
        "\n",
        "**Mamba SSM + Mixture of Experts ‚Äî From Scratch**\n",
        "\n",
        "Built by Iseer & Co.\n",
        "\n",
        "---\n",
        "\n",
        "‚ö†Ô∏è **Before running:** Go to `Runtime > Change runtime type > GPU (T4)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "check-gpu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "\n",
            "PyTorch: 2.9.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q einops wandb datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "clone-repo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'IseerArchitecture'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: 'IseerArchitecture'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Clone the Iseer repository\n",
        "!git clone https://github.com/InanXR/IseerArchitecture.git\n",
        "%cd IseerArchitecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-header"
      },
      "source": [
        "## 2Ô∏è‚É£ Load Model & Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "load-model"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'iseer'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2826499843.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0miseer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mISEER_SM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mISEER_MD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0miseer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miseer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIseer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0miseer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBPETokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'iseer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from iseer.model.config import ISEER_SM, ISEER_MD\n",
        "from iseer.model.iseer import Iseer\n",
        "from iseer.tokenizer.bpe import BPETokenizer\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = BPETokenizer.load('iseer/tokenizer/vocab.json')\n",
        "print(f\"Vocabulary size: {len(tokenizer):,}\")\n",
        "\n",
        "# Create model\n",
        "config = ISEER_SM\n",
        "config.vocab_size = len(tokenizer)\n",
        "model = Iseer(config)\n",
        "\n",
        "total, active = model.count_parameters()\n",
        "print(f\"Total params: {total:,}\")\n",
        "print(f\"Active params: {active:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-header"
      },
      "source": [
        "## 3Ô∏è‚É£ Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-data-hf"
      },
      "outputs": [],
      "source": [
        "# Option A: Load from HuggingFace\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Bengali data\n",
        "print(\"Loading Bengali data...\")\n",
        "bn_data = load_dataset(\"cc100\", lang=\"bn\", split=\"train\", streaming=True)\n",
        "bn_texts = [item['text'][:2000] for i, item in enumerate(bn_data) if i < 25000]\n",
        "print(f\"  Loaded {len(bn_texts):,} Bengali texts\")\n",
        "\n",
        "# English data\n",
        "print(\"Loading English data...\")\n",
        "en_data = load_dataset(\"cc100\", lang=\"en\", split=\"train\", streaming=True)\n",
        "en_texts = [item['text'][:2000] for i, item in enumerate(en_data) if i < 25000]\n",
        "print(f\"  Loaded {len(en_texts):,} English texts\")\n",
        "\n",
        "texts = bn_texts + en_texts\n",
        "print(f\"\\nTotal: {len(texts):,} texts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create-dataloader"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "from iseer.data.dataset import create_dataloader\n",
        "\n",
        "train_loader = create_dataloader(\n",
        "    texts=texts,\n",
        "    tokenizer=tokenizer,\n",
        "    batch_size=8,\n",
        "    seq_len=512,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-header"
      },
      "source": [
        "## 4Ô∏è‚É£ Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "from iseer.training.trainer import Trainer, TrainingConfig\n",
        "\n",
        "# Training config\n",
        "train_config = TrainingConfig(\n",
        "    learning_rate=3e-4,\n",
        "    max_steps=5000,\n",
        "    warmup_steps=100,\n",
        "    batch_size=8,\n",
        "    gradient_accumulation_steps=4,\n",
        "    mixed_precision=True,\n",
        "    dtype=\"float16\",\n",
        "    log_steps=50,\n",
        "    save_steps=1000,\n",
        "    output_dir=\"checkpoints\",\n",
        "    use_wandb=False,  # Set True to log to wandb\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataloader=train_loader,\n",
        "    config=train_config,\n",
        ")\n",
        "\n",
        "# Train!\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generate-header"
      },
      "source": [
        "## 5Ô∏è‚É£ Test Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate"
      },
      "outputs": [],
      "source": [
        "# Test the trained model\n",
        "model.eval()\n",
        "\n",
        "prompts = [\n",
        "    \"‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂ ‡¶è‡¶ï‡¶ü‡¶ø\",\n",
        "    \"The capital of France is\",\n",
        "    \"In the beginning\",\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    output = model.generate(\n",
        "        tokenizer.encode(prompt, add_special_tokens=False),\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.8,\n",
        "    )\n",
        "    print(f\"Output: {tokenizer.decode(output)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save-header"
      },
      "source": [
        "## 6Ô∏è‚É£ Save & Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save-download"
      },
      "outputs": [],
      "source": [
        "# Save final model\n",
        "torch.save(model.state_dict(), 'iseer_sm_trained.pt')\n",
        "print(\"Model saved to iseer_sm_trained.pt\")\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download('iseer_sm_trained.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "footer"
      },
      "source": [
        "---\n",
        "\n",
        "**üß¨ Built with Iseer Architecture**\n",
        "\n",
        "Mamba SSM + MoE | From Scratch | By Iseer & Co."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
